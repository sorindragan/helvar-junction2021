{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6614fa3f",
   "metadata": {},
   "source": [
    "<h1>Helvar Starter Kit</h1>\n",
    "<h3>Welcome to Helvar's Junction Challenge!</h3>\n",
    "<p>This notebook is to help you get acquainted with the dataset. You can follow the instructions to easily load and visualize datasets. However, this is only for convenience purposes. You are welcome to use whatever tools you are comfortable with, as we are only interested in results!</p>\n",
    "<p>Let's Begin by first loading all necessary libraries for this notebook to run.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c860e7-159a-44d3-b937-b0292e6b5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "import imageio as iio\n",
    "from plotting import Plotting\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d68ab6",
   "metadata": {},
   "source": [
    "<p>This starter kit contains sample datafiles. You can also download the full datasets in the README document. Please remember to place the downloaded zip file in the data folder and unzip it.</p>\n",
    "<ol>\n",
    "<li>First load the pickle file and convert the timestamps to Helsinki timezone</li>\n",
    "<li>Next load the json file containing deviceids</li>\n",
    "<li>Finally load the png file as both a numpy array and a base64 encoded image. We need the later for plotting in Plotly helper functions</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f7568b-fbee-49eb-a966-87ee9556479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'site_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e4053-b1bd-491c-b95a-a4249d5830ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = pd.read_pickle(f'./data/{site}/{site}.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6a3ab-08ff-4ff5-9ab1-0ad383c4c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.loc[:, 'timestamp'] = (pd.to_datetime(df_events['timestamp'], utc=True)\n",
    "                                 .dt.tz_convert('Europe/Helsinki')\n",
    "                                 .dt.tz_localize(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff71e3-ce6c-4b17-8bce-81a0555de690",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c7d63-b42d-479d-8a25-c7303771d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devices = pd.read_json(f'./data/{site}/{site}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2085d9da-02db-426a-ad23-6d7b5c12e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devices.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bf423-48c0-4963-8bd3-43062cca7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/{site}/{site}.png', \"rb\") as image_file:\n",
    "    encoded_string = base64.b64encode(image_file.read()).decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f4aeb-533e-4b87-a865-00ab4027a21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = iio.imread(f'./data/{site}/{site}.png')\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19d9ced-6093-4601-860e-3c8e4ac8c124",
   "metadata": {},
   "source": [
    "We can now load the floorplan just to get a feel of what the devices look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41bd7d-8dfc-4d83-9134-b6ad36548e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factor = 3 # Set to 1 for highest resolution\n",
    "plotting_obj = Plotting(bg_img=encoded_string, dims=(img.shape[1], img.shape[0]), df_devices=df_devices, scaling_factor=scaling_factor)\n",
    "plotting_obj.run(renderer='browser') # Switch to iframe if you would like to view it here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6580dd-a272-45ae-8ab4-4d929ffb0bd7",
   "metadata": {},
   "source": [
    "## View Occupancy by Day\n",
    "<p>Since we are dealing with irregular IoT event data, we need to define our time-series window size and compute a statistic for the events during that window. This example shows the sum of events per day. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f19638-d0b4-4ea5-8ea4-a5973f87b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_day = df_events.copy()\n",
    "df_events_day.loc[:, 'timestamp'] = df_events_day['timestamp'].dt.floor('1D')\n",
    "df_events_day.loc[:, 'value'] = 1.0\n",
    "df_events_day = df_events_day.groupby('timestamp').sum()\n",
    "df_events_day = df_events_day.drop(['deviceid'], axis=1)\n",
    "df_events_day = df_events_day.reindex(pd.date_range(df_events_day.index.min(), df_events_day.index.max(), freq='1D')).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63dc11-4314-4ef2-8fdd-25f493cbc5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_day.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cb29c-159d-4482-8a74-29eba3862f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter(x=df_events_day.index, y=df_events_day['value'])],\n",
    "                layout=dict(height=500, width=1000))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781e068-b2b7-402f-824e-d018198671e3",
   "metadata": {},
   "source": [
    "## Animate Data\n",
    "\n",
    "<p>The plotting helper script contains an animation engine utilising Plotly. It is extremely simple to use. Here is an example where we aggregate data into 5 minute bins, and then visualize how motion sensors are triggered through 1 day. You can choose different time intervals, but please remember that higher time granularities can end up rendering a lot of frames and might lead to performance issues. In this example, the total number of frames is (60//5) * 24 = 288</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5f741-80cd-48dd-bc6a-98c2b5dc16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_day = df_events[df_events.timestamp.dt.date.astype(str) == \"2021-08-05\"].copy()\n",
    "df_events_day.timestamp = df_events_day.timestamp.dt.floor('5min')\n",
    "df_events_day.loc[:, 'b'] = 1\n",
    "df_events_day = df_events_day.groupby(['deviceid', 'timestamp']).sum()\n",
    "df_events_day = df_events_day.pivot_table(index='timestamp', columns='deviceid', values='b')\n",
    "df_events_day = df_events_day.reindex(pd.date_range(df_events_day.index.min().floor('1D'), df_events_day.index.max().ceil('1D'), freq='5min', closed='left')).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a5fe8-6c0b-4a50-ad41-291b78d4f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = df_events_day.to_dict(orient='records')\n",
    "ts = df_events_day.reset_index()[['index']].astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c13e1d-2259-4587-9197-9c9bc9ba1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_obj = Plotting(bg_img=encoded_string, dims=(img.shape[1], img.shape[0]), df_devices=df_devices, scaling_factor=3)\n",
    "plotting_obj.populate_data(frames, ts)\n",
    "plotting_obj.run(renderer='browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aa8874-4ef6-4d04-90d4-6c21ba130007",
   "metadata": {},
   "source": [
    "## Challenge Category 1\n",
    "<p>For the first challenge, we want to solve a real-world problem of indoor device mapping. The floorplans we have provided you with already contain mapped devices, meaning they have defined locations on a floorplan. In reality, this takes a lot of time. We physically need to identify each device inside the building and place them on a floorplan. The objective of this exercise is to come up with ways to speed up this process. We have written down some ideas below, however feel free to be creative! You can come up with entirely new ideas of your own.</p>\n",
    "\n",
    "#### Example Aproach:\n",
    "<p>Let's assume the floorplan contains 500 devices. We can delete 400 devices, and use the occupancy events data to identify neighbours. Once the neighbours have been identified, we can simply use the data to locate the missing 400 devices! This means our engineers only need to locate 100 devices, and let the system run for N days and then find the rest.</p> \n",
    "<p>The Machine Learning aspect of the challenge comes from: 1. increasing the number of deleted devices, and 2. the smallest possible value of N that gives the best mappings. You can use Euclidean distance between the predicted location of the object and the actual location from our provided floorplans to determine accuracy of your algorithm. We have provided 5 different sites with a variety of device configurations and data, so be sure to properly create Training and Test Datasets!</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305f900-bfce-4970-ad1b-c17022574d4c",
   "metadata": {},
   "source": [
    "## Challenge Category 2\n",
    "<p>The second challenge is more about providing value to the client. We have provided data from real-world buildings. These buildings are occupied according to certain predictable patterns. For example a school might only observe occupancy during the morning. A hospital or a shopping mall might observe occupancy throughout the day. The objective of this exercise is to determine how people move through buildings by combining spatial and temporal data. </p>\n",
    "\n",
    "#### Example Aproach:\n",
    "<p>We can define a graph network of devices, with the edge weights representing the distance between devices. Then depending on the proximity of devices and the correlation of events within a certain time-window, say 15 minutes, we can cluster the most frequently visited spaces in a building. By creating similar sequences across the day, week or month we can determine patterns that show us how the building is used at different times of the day, or different days of the week etc. We can also try to figure out which paths are dominant and which are used least frequently. Such information is extremely valuable to building owners and tenants.</p> \n",
    "<p>You can experiment with different windowing approaches. Try to think about what sort of metrics are important. Is it really worth investigaing how the occupancy changes at midnight, or is it worth understanding how people move through the building at 9AM? Also, does the pattern change during the week, for example do more people visit on Monday or Friday?</p>\n",
    "<p>We would love to see your ideas on what is the best way to present the results of this type of data analysis to the customers. UI/UX experts, we're looking at you!</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4b38b0-fb81-4dfc-be88-a974cba3f355",
   "metadata": {},
   "source": [
    "## Challenge Category 3\n",
    "<p>The last challenge is related to a type of sensor that is not common in smart buildings at the moment: audio sensors. We have availabe motion sensors that generate occupancy data, but we decided to augmnet that with audio data. We want to explore the utility of incorporating more data sources in a smart building.</p>\n",
    "<p>The data collection is done at a garage, and contains 4 audio sensors placed in a rectangular grid. There is a lot of activity happening in the garage: people are walking, driving their car, or bicycles. The objective would be to identify these events by combining the audio streams from all the 4 sensors and by incorporating motion data to pinpoint where the activity was taking place.</p>\n",
    "\n",
    "#### Example Aproach:\n",
    "<p>This is an extremely open ended challenge. There are numerous ways this can be tackled. Clever audio signal processing, or using deep learning to detect events. The choice is yours.</p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
